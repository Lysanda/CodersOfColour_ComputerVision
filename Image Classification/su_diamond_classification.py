# -*- coding: utf-8 -*-
"""SU Diamond Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U8auHhmfV-WJzRnFIjwfIPm4OtGo2_T3

## Step 1: Setup the libraries and introduce the dataset
"""

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import time
import os
import copy
from torch.utils.data import Dataset, DataLoader

import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

plt.ion()   # interactive mode

"""### Download the dataset we would be using"""

!wget -c "https://github.com/Lysanda/CodersOfColour_ComputerVision/raw/master/Image%20Classification/datacol.zip"

!unzip datacol.zip

"""### Resize, reshape and augment the dataset
---
The various images in our dataset do not have the same shape and size, we therefore resize and reshape them so they have the same size and shape
"""

data_transforms_wo_normalization = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

"""### Load the dataset and set up normalization"""

data_dir = 'datacol'
batch_size = 4

train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),
                                          data_transforms_wo_normalization['train'])

train_dataloader = DataLoader(train_dataset, batch_size=batch_size,
                                             shuffle=True)

train_dataloader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)
data = next(iter(train_dataloader))

custom_mean = []
custom_std = []

for channels in range(3):
  custom_mean.append(data[0][:, channels, :, :].mean())
  custom_std.append(data[0][:, channels, :, :].std())

print("Mean: ", custom_mean)
print("STD: ", custom_std)

data_transforms_with_normalization = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(custom_mean, custom_std)
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(custom_mean, custom_std)
    ]),
}

train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),
                                          data_transforms_with_normalization['train'])

train_dataloader = DataLoader(train_dataset, batch_size=batch_size,
                                             shuffle=True)

test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'),
                                          data_transforms_with_normalization['val'])

test_dataloader = DataLoader(test_dataset, batch_size=batch_size,
                                             shuffle=True)

class_names = train_dataset.classes
print("CLASSES: ", class_names)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

dataloader = {'train': train_dataloader,
              'val': test_dataloader}

dataset_sizes = {'train': len(train_dataset),
              'val': len(test_dataset)}

"""## Step 2: Visualizing some of the images

### Setup function for visualizing dataset images
"""

def imshow(inp, title=None):
    """Imshow for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array(custom_mean)
    std = np.array(custom_std)
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated

"""### Displaying some of the images"""

# Get a batch of training data
inputs, classes = next(iter(test_dataloader))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])

"""## Step 3: Training the model

### Define the function to implement training and evaluating the model
"""

training_loss = []
test_loss = []

training_accuracy = []
test_accuracy = []

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
  since = time.time() # To measure time taken to build and train the model

  best_model_wts = copy.deepcopy(model.state_dict()) # Save weight of best model
  best_acc = 0.0 # Save best accuracy

  for epoch in range(num_epochs):
    print('Epoch {}/{}'.format(epoch, num_epochs - 1))
    print('-' * 10)

    # Each epoch has its training and validation
    for phase in ['train', 'val']:
      if phase == 'train':
        model.train()
      else:
        model.eval()

      running_loss = 0.0
      running_corrects = 0

      for inputs, labels in dataloader[phase]:
        inputs = inputs.to(device) # Move data to GPU if you are using GPU
        labels = labels.to(device) # Move data to GPU if you are using GPU

        optimizer.zero_grad() # Set gradients to zero so it does not accumulate

        with torch.set_grad_enabled(phase == 'train'): # Train in train phase
          outputs = model(inputs)
          _, preds = torch.max(outputs, 1)
          loss = criterion(outputs, labels) # Compare ground truth with outputs

          # Backward propagation if in train mode
          if phase == 'train':
            loss.backward()
            optimizer.step()

        # Compute loss and accuracy
        running_loss += loss.item() * inputs.size(0)
        
        
        running_corrects += torch.sum(preds == labels.data)

      if phase =='train':
        scheduler.step()

      
      epoch_loss = running_loss / dataset_sizes[phase]
      epoch_acc = running_corrects.double() / dataset_sizes[phase]

      if phase == 'train':
        training_loss.append(epoch_loss)
        training_accuracy.append(epoch_acc)
      else:
        test_loss.append(running_loss)
        test_accuracy.append(epoch_acc)

      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

      # deep copy the model
      if phase == 'val' and epoch_acc > best_acc:
        best_acc = epoch_acc
        best_model_wts = copy.deepcopy(model.state_dict())

    print()

  time_elapsed = time.time() - since
  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
  print('Best val Acc: {:4f}'.format(best_acc))

  model.load_state_dict(best_model_wts) # Load the best model weights
  return model

"""### Finetuning the model we choose to use"""

model_ft = models.resnet18(pretrained=True) # Choose a model to use
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.
# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).
model_ft.fc = nn.Linear(num_ftrs, len(class_names))

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

"""## Step 4: Visualizing the results

### Setup function to visualize results of the model
"""

def visualize_model(model, num_images=6):
  was_training = model.training

  model.eval()
  images_so_far = 0
  fig = plt.figure()

  with torch.no_grad():
    for i, (inputs, labels) in enumerate(dataloader['val']):
      inputs = inputs.to(device)
      labels = labels.to(device)

      outputs = model(inputs)
      _, preds = torch.max(outputs, 1)

      for j in range(inputs.size()[0]):
        images_so_far += 1
        ax = plt.subplot(num_images//2, 2, images_so_far)

        ax.axis('off')
        ax.set_title('predicted: {}'.format(class_names[preds[j]]))
        imshow(inputs.cpu().data[j])

        if images_so_far == num_images:
          model.train(mode=was_training)
          return

    model.train(mode=was_training)

"""### Show model predictions"""

visualize_model(model_ft)
plt.ioff()
plt.show()

"""## Step 5: Plot the graph for accuracy and loss

### Training and test loss
"""

fig = plt.figure()
plt.plot(training_loss, color='blue')
plt.plot(test_loss, color='red')
plt.legend(['Train Loss', 'Test Loss'], loc='upper right')
plt.xlabel('Number of epoch completed')
plt.ylabel('negative log likelihood loss')

"""### Training and test accuracy"""

fig = plt.figure()
plt.plot(training_accuracy, color='blue')
plt.plot(test_accuracy, color='red')
plt.legend(['Train Accuracy', 'Test Accuracy'], loc='upper left')
plt.xlabel('Number of epoch completed')
plt.ylabel('negative log likelihood loss')

"""## Step 6: Plotting the confusion matrix"""

@torch.no_grad() # this functions execution omits gradient tracking.
def get_all_preds(model, loader):
    all_preds = torch.tensor([]).cuda()
    for batch in loader:
        images, labels = batch
        images, labels = images.cuda(), labels.cuda() 

        preds = model(images)
        preds = preds.cuda()
        all_preds = torch.cat(
            (all_preds, preds)
            ,dim=0
        )
    return all_preds

all_preds = get_all_preds(model_ft, test_dataloader)
with torch.no_grad():
    prediction_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10000)
    test_preds = get_all_preds(model_ft, prediction_loader)

def get_pred_as_list(test_preds):
  test_preds = (test_preds.max(1, keepdim=True)[1]).tolist()

  result = []
  for i in range(len(test_preds)):
    result.append(test_preds[i][0])

  return result

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

test_preds = get_pred_as_list(test_preds)

accuracy_score = accuracy_score(test_preds, test_dataset.targets)
print('Accuracy score: {0:0.2f}'.format(accuracy_score))

cmt = torch.zeros(len(class_names),len(class_names), dtype=torch.int64)
for i in range(len(test_preds)):
  tl = test_dataset.targets[i]
  pl = test_preds[i]

  cmt[tl, pl] = cmt[tl, pl] + 1

plt.figure(figsize=(5,5))
plot_confusion_matrix(cmt, test_dataset.classes)

"""### Predict an Image"""

import PIL

transform = data_transforms_with_normalization['val']

PATH_TO_IMAGE = '/content/test1.jpg'
img = PIL.Image.open(PATH_TO_IMAGE)  # Load image as PIL.Image
x = transform(img)  # Preprocess image
x = x.unsqueeze(0).cuda()  # Add batch dimension

output = model_ft(x)  # Forward pass
pred = torch.argmax(output, 1)  # Get predicted class if multi-class classification
im = PIL.Image.open(PATH_TO_IMAGE)
im.show()
print('Image predicted as ', class_names[pred.item()])

from IPython.display import Image, display
display(Image(PATH_TO_IMAGE))